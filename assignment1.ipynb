{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data]    | Downloading package inaugural to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
      "[nltk_data]    | Downloading package stopwords to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data]    | Downloading package treebank to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package omw to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\omw.zip.\n",
      "[nltk_data]    | Downloading package wordnet to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Prashant\n",
      "[nltk_data]    |     Mourya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"popular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "panctuations = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ('Time was, with most of us, when Christmas Day encircling all our limited world like a magic ring, left nothing out for us to miss or seek; bound together all our home enjoyments, affections, and hopes; grouped everything and every one around the Christmas fire; and made the little picture shining in our bright young eyes, complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Time was, with most of us, when Christmas Day encircling all our limited world like a magic ring, left nothing out for us to miss or seek; bound together all our home enjoyments, affections, and hopes; grouped everything and every one around the Christmas fire; and made the little picture shining in our bright young eyes, complete.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time was, with most of us, when Christmas Day encircling all our limited world like a magic ring, left nothing out for us to miss or seek; bound together all our home enjoyments, affections, and hopes; grouped everything and every one around the Christmas fire; and made the little picture shining in our bright young eyes, complete.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'was', ',', 'with', 'most', 'of', 'us', ',', 'when', 'Christmas', 'Day', 'encircling', 'all', 'our', 'limited', 'world', 'like', 'a', 'magic', 'ring', ',', 'left', 'nothing', 'out', 'for', 'us', 'to', 'miss', 'or', 'seek', ';', 'bound', 'together', 'all', 'our', 'home', 'enjoyments', ',', 'affections', ',', 'and', 'hopes', ';', 'grouped', 'everything', 'and', 'every', 'one', 'around', 'the', 'Christmas', 'fire', ';', 'and', 'made', 'the', 'little', 'picture', 'shining', 'in', 'our', 'bright', 'young', 'eyes', ',', 'complete', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stpwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time us Christmas Day encircle limit world like magic ring leave nothing us miss seek bind together home enjoyments affections hop group everything every one around Christmas fire make little picture shin bright young eye complete']\n"
     ]
    }
   ],
   "source": [
    "#Lemmatizing\n",
    "sentences = sent_tokenize(sentence)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word,pos=\"v\") for word in words if (word not in stpwords and word not in panctuations)]\n",
    "    sentences[i] = \" \".join(words)\n",
    "print(sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
