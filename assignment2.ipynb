{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize,WhitespaceTokenizer,TreebankWordTokenizer\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stpwords = set(stopwords.words('english'))\n",
    "panctuations = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ('No! Far be such miscalled philosophy from us, dear Reader, on Christmas Day! Nearer and closer to our hearts be the Christmas spirit, which is the spirit of active usefulness, perseverance, cheerful discharge of duty, kindness and forbearance! It is in the last virtues especially, that we are, or should be, strengthened by the unaccomplished visions of our youth; for, who shall say that they are not our teachers to deal gently even with the impalpable nothings of the earth!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No!',\n",
       " 'Far be such miscalled philosophy from us, dear Reader, on Christmas Day!',\n",
       " 'Nearer and closer to our hearts be the Christmas spirit, which is the spirit of active usefulness, perseverance, cheerful discharge of duty, kindness and forbearance!',\n",
       " 'It is in the last virtues especially, that we are, or should be, strengthened by the unaccomplished visions of our youth; for, who shall say that they are not our teachers to deal gently even with the impalpable nothings of the earth!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Divide into the sentences\n",
    "sent_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " '!',\n",
       " 'Far',\n",
       " 'be',\n",
       " 'such',\n",
       " 'miscalled',\n",
       " 'philosophy',\n",
       " 'from',\n",
       " 'us',\n",
       " ',',\n",
       " 'dear',\n",
       " 'Reader',\n",
       " ',',\n",
       " 'on',\n",
       " 'Christmas',\n",
       " 'Day',\n",
       " '!',\n",
       " 'Nearer',\n",
       " 'and',\n",
       " 'closer',\n",
       " 'to',\n",
       " 'our',\n",
       " 'hearts',\n",
       " 'be',\n",
       " 'the',\n",
       " 'Christmas',\n",
       " 'spirit',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'the',\n",
       " 'spirit',\n",
       " 'of',\n",
       " 'active',\n",
       " 'usefulness',\n",
       " ',',\n",
       " 'perseverance',\n",
       " ',',\n",
       " 'cheerful',\n",
       " 'discharge',\n",
       " 'of',\n",
       " 'duty',\n",
       " ',',\n",
       " 'kindness',\n",
       " 'and',\n",
       " 'forbearance',\n",
       " '!',\n",
       " 'It',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'last',\n",
       " 'virtues',\n",
       " 'especially',\n",
       " ',',\n",
       " 'that',\n",
       " 'we',\n",
       " 'are',\n",
       " ',',\n",
       " 'or',\n",
       " 'should',\n",
       " 'be',\n",
       " ',',\n",
       " 'strengthened',\n",
       " 'by',\n",
       " 'the',\n",
       " 'unaccomplished',\n",
       " 'visions',\n",
       " 'of',\n",
       " 'our',\n",
       " 'youth',\n",
       " ';',\n",
       " 'for',\n",
       " ',',\n",
       " 'who',\n",
       " 'shall',\n",
       " 'say',\n",
       " 'that',\n",
       " 'they',\n",
       " 'are',\n",
       " 'not',\n",
       " 'our',\n",
       " 'teachers',\n",
       " 'to',\n",
       " 'deal',\n",
       " 'gently',\n",
       " 'even',\n",
       " 'with',\n",
       " 'the',\n",
       " 'impalpable',\n",
       " 'nothings',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Tokenization(Divide the sentences into words)\n",
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No!',\n",
       " 'Far',\n",
       " 'be',\n",
       " 'such',\n",
       " 'miscalled',\n",
       " 'philosophy',\n",
       " 'from',\n",
       " 'us,',\n",
       " 'dear',\n",
       " 'Reader,',\n",
       " 'on',\n",
       " 'Christmas',\n",
       " 'Day!',\n",
       " 'Nearer',\n",
       " 'and',\n",
       " 'closer',\n",
       " 'to',\n",
       " 'our',\n",
       " 'hearts',\n",
       " 'be',\n",
       " 'the',\n",
       " 'Christmas',\n",
       " 'spirit,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'the',\n",
       " 'spirit',\n",
       " 'of',\n",
       " 'active',\n",
       " 'usefulness,',\n",
       " 'perseverance,',\n",
       " 'cheerful',\n",
       " 'discharge',\n",
       " 'of',\n",
       " 'duty,',\n",
       " 'kindness',\n",
       " 'and',\n",
       " 'forbearance!',\n",
       " 'It',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'last',\n",
       " 'virtues',\n",
       " 'especially,',\n",
       " 'that',\n",
       " 'we',\n",
       " 'are,',\n",
       " 'or',\n",
       " 'should',\n",
       " 'be,',\n",
       " 'strengthened',\n",
       " 'by',\n",
       " 'the',\n",
       " 'unaccomplished',\n",
       " 'visions',\n",
       " 'of',\n",
       " 'our',\n",
       " 'youth;',\n",
       " 'for,',\n",
       " 'who',\n",
       " 'shall',\n",
       " 'say',\n",
       " 'that',\n",
       " 'they',\n",
       " 'are',\n",
       " 'not',\n",
       " 'our',\n",
       " 'teachers',\n",
       " 'to',\n",
       " 'deal',\n",
       " 'gently',\n",
       " 'even',\n",
       " 'with',\n",
       " 'the',\n",
       " 'impalpable',\n",
       " 'nothings',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#White Space Tokenization(Tokenize the sentence based on space)\n",
    "WhitespaceTokenizer().tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " '!',\n",
       " 'Far',\n",
       " 'be',\n",
       " 'such',\n",
       " 'miscalled',\n",
       " 'philosophy',\n",
       " 'from',\n",
       " 'us',\n",
       " ',',\n",
       " 'dear',\n",
       " 'Reader',\n",
       " ',',\n",
       " 'on',\n",
       " 'Christmas',\n",
       " 'Day',\n",
       " '!',\n",
       " 'Nearer',\n",
       " 'and',\n",
       " 'closer',\n",
       " 'to',\n",
       " 'our',\n",
       " 'hearts',\n",
       " 'be',\n",
       " 'the',\n",
       " 'Christmas',\n",
       " 'spirit',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'the',\n",
       " 'spirit',\n",
       " 'of',\n",
       " 'active',\n",
       " 'usefulness',\n",
       " ',',\n",
       " 'perseverance',\n",
       " ',',\n",
       " 'cheerful',\n",
       " 'discharge',\n",
       " 'of',\n",
       " 'duty',\n",
       " ',',\n",
       " 'kindness',\n",
       " 'and',\n",
       " 'forbearance',\n",
       " '!',\n",
       " 'It',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'last',\n",
       " 'virtues',\n",
       " 'especially',\n",
       " ',',\n",
       " 'that',\n",
       " 'we',\n",
       " 'are',\n",
       " ',',\n",
       " 'or',\n",
       " 'should',\n",
       " 'be',\n",
       " ',',\n",
       " 'strengthened',\n",
       " 'by',\n",
       " 'the',\n",
       " 'unaccomplished',\n",
       " 'visions',\n",
       " 'of',\n",
       " 'our',\n",
       " 'youth',\n",
       " ';',\n",
       " 'for',\n",
       " ',',\n",
       " 'who',\n",
       " 'shall',\n",
       " 'say',\n",
       " 'that',\n",
       " 'they',\n",
       " 'are',\n",
       " 'not',\n",
       " 'our',\n",
       " 'teachers',\n",
       " 'to',\n",
       " 'deal',\n",
       " 'gently',\n",
       " 'even',\n",
       " 'with',\n",
       " 'the',\n",
       " 'impalpable',\n",
       " 'nothings',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " '!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses regular expressions to tokenize text\n",
    "TreebankWordTokenizer().tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Root Word           \n",
      "No                  No                  \n",
      "Far                 far                 \n",
      "miscalled           miscal              \n",
      "philosophy          philosophi          \n",
      "us                  us                  \n",
      "dear                dear                \n",
      "Reader              reader              \n",
      "Christmas           christma            \n",
      "Day                 day                 \n",
      "Nearer              nearer              \n",
      "closer              closer              \n",
      "hearts              heart               \n",
      "Christmas           christma            \n",
      "spirit              spirit              \n",
      "spirit              spirit              \n",
      "active              activ               \n",
      "usefulness          use                 \n",
      "perseverance        persever            \n",
      "cheerful            cheer               \n",
      "discharge           discharg            \n",
      "duty                duti                \n",
      "kindness            kind                \n",
      "forbearance         forbear             \n",
      "It                  It                  \n",
      "last                last                \n",
      "virtues             virtu               \n",
      "especially          especi              \n",
      "strengthened        strengthen          \n",
      "unaccomplished      unaccomplish        \n",
      "visions             vision              \n",
      "youth               youth               \n",
      "shall               shall               \n",
      "say                 say                 \n",
      "teachers            teacher             \n",
      "deal                deal                \n",
      "gently              gentli              \n",
      "even                even                \n",
      "impalpable          impalp              \n",
      "nothings            noth                \n",
      "earth               earth               \n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "sentences = sent_tokenize(sentence)\n",
    "stemmer = PorterStemmer()\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Root Word\"))\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    for word in words:\n",
    "        if (word not in stpwords and word not in panctuations):\n",
    "            print(\"{0:20}{1:20}\".format(word,stemmer.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "No                  No                  \n",
      "Far                 Far                 \n",
      "miscalled           miscall             \n",
      "philosophy          philosophy          \n",
      "us                  u                   \n",
      "dear                dear                \n",
      "Reader              Reader              \n",
      "Christmas           Christmas           \n",
      "Day                 Day                 \n",
      "Nearer              Nearer              \n",
      "closer              close               \n",
      "hearts              heart               \n",
      "Christmas           Christmas           \n",
      "spirit              spirit              \n",
      "spirit              spirit              \n",
      "active              active              \n",
      "usefulness          usefulness          \n",
      "perseverance        perseverance        \n",
      "cheerful            cheerful            \n",
      "discharge           discharge           \n",
      "duty                duty                \n",
      "kindness            kindness            \n",
      "forbearance         forbearance         \n",
      "It                  It                  \n",
      "last                last                \n",
      "virtues             virtue              \n",
      "especially          especially          \n",
      "strengthened        strengthen          \n",
      "unaccomplished      unaccomplished      \n",
      "visions             vision              \n",
      "youth               youth               \n",
      "shall               shall               \n",
      "say                 say                 \n",
      "teachers            teacher             \n",
      "deal                deal                \n",
      "gently              gently              \n",
      "even                even                \n",
      "impalpable          impalpable          \n",
      "nothings            nothing             \n",
      "earth               earth               \n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "#Function to convert nltk tag to wordnet tag\n",
    "def nltk_to_wordnet(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "sentences = sent_tokenize(sentence)\n",
    "lematizer = WordNetLemmatizer()\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    nltk_tagged = pos_tag(words)\n",
    "    wordnet_tagged = map(lambda x:(x[0],nltk_to_wordnet(x[1])),nltk_tagged)\n",
    "    for word,tag in wordnet_tagged:\n",
    "        if (word not in stpwords and word not in panctuations):\n",
    "            if tag is not None:\n",
    "                print(\"{0:20}{1:20}\".format(word,lematizer.lemmatize(word,tag)))\n",
    "            else:\n",
    "                print(\"{0:20}{1:20}\".format(word,lematizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I----->None\n",
      "am----->v\n",
      "going----->v\n",
      "to----->None\n",
      "school----->n\n"
     ]
    }
   ],
   "source": [
    "nltk_taged = pos_tag(['I','am','going','to','school'])\n",
    "wordnet_tagged = map(lambda x:(x[0],nltk_to_wordnet(x[1])),nltk_taged)\n",
    "for word,tag in wordnet_tagged:\n",
    "    print(f\"{word}----->{tag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
